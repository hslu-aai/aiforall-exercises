{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Training a CNN for Classification\n",
    "Convolutional neural networks (CNN) are a type of artificial neural network especially designed for processing images, i.e. matrices of color intensity values. There are various kinds of layers in a CNN, but a typical architecture is to build a sequence of *convolutional* layers that find patterns in individual areas of the input matrix and *pooling* layers that aggregate these patterns. The final layers *flatten* the matrix data in order to perform classification with a standard *dense* or *fully connected* layer.\n",
    "\n",
    "In this exercise we will consider CNNs for the classification of blood cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries and tools"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!pip3 install numpy medmnist pandas scipy keras tf-keras-vis tensorflow",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import medmnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from medmnist import BloodMNIST\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tf_keras_vis.activation_maximization import ActivationMaximization\n",
    "from tf_keras_vis.activation_maximization.callbacks import Progress\n",
    "from tf_keras_vis.activation_maximization.input_modifiers import Jitter, Rotate2D\n",
    "from tf_keras_vis.utils.model_modifiers import ExtractIntermediateLayer, ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def show_history_plots_of_trained_model(history, fill_between=True) -> None:\n",
    "    acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "    val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs_range = range(len(val_loss))\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label=\"training accuracy\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"validation accuracy\")\n",
    "    if fill_between:\n",
    "        plt.fill_between(epochs_range, acc, val_acc, color=\"lightpink\", alpha=0.4, hatch=\"-\", label=\"difference\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"training and validation accuracy\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label=\"training loss\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"validation loss\")\n",
    "    if fill_between:\n",
    "        plt.fill_between(epochs_range, loss, val_loss, color=\"lightpink\", alpha=0.4, hatch=\"-\", label=\"difference\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"training and validation loss\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we should inspect the metadata to get more insights into what kind of data we are dealing with. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "medmnist.INFO[\"bloodmnist\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the description and the label field, we discover that we have images of normal blood cells organized into 8 classes including types of white/red blood cells and blood platelets. Now we download the data for the train, validation, test splits and define what size of images we want to use. Since this is a benchmark dataset, the splits are predefined to enable comparisons between studies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train = BloodMNIST(split=\"train\", download=True, as_rgb=True, size=28)\n",
    "val = BloodMNIST(split=\"val\", download=True, as_rgb=True, size=28)\n",
    "test = BloodMNIST(split=\"test\", download=True, as_rgb=True, size=28)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.unique(train.labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the labels are indeed integers. We can create our own map so we do not have to deal with class indices during exploration and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels = {int(label_idx): label_name  # since we have strings in the metadata\n",
    "          for label_idx, label_name in medmnist.INFO[\"bloodmnist\"][\"label\"].items()}\n",
    "labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets change the name of label 3 to something more concise so we have no clutter in our plots:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels[3] = \"immature granulocytes\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train.imgs[0][0][:10]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images seem to be scaled between 0-255 in RGB. Since we pass them to a CNN, which operates in floating point, we should scale the images to a float between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train.imgs = train.imgs / 255.0\n",
    "val.imgs = val.imgs / 255.0\n",
    "test.imgs = test.imgs / 255.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an intuition what a model should learn, we can plot a few example for each label"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare a dictionary to store 5 examples for each label\n",
    "examples = {label: [] for label in labels.keys()}\n",
    "\n",
    "# Collect 5 examples for each label\n",
    "for img, lbl in zip(train.imgs, train.labels):\n",
    "    if len(examples[lbl[0]]) < 5:\n",
    "        examples[lbl[0]].append(img)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(8, 5, figsize=(10, 15))\n",
    "fig.suptitle(\"5 examples for each label\", fontsize=16)\n",
    "\n",
    "for label, example_images in examples.items():\n",
    "    for i, img in enumerate(example_images):\n",
    "        ax = axs[label, i]\n",
    "        ax.imshow(img, vmin=0, vmax=1)  # Assuming grayscale images, adjust if needed\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_title(labels[label], fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)  # Adjust top for main title\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that every good machine learning engineer should at this point check for potential issues in the data, and preprocess it as appropriate.\n",
    "In this guided exercise we will completely ignore this phase; please **never** do this with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is definitely some difference between the classes even visible for a layperson. Thus we are confident, that we can build a classifier using a CNN."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "def count_labels(labels, classnames):\n",
    "    classnames = list(classnames)\n",
    "    dictionary = dict.fromkeys(classnames, 0)\n",
    "    for label in labels:\n",
    "        dictionary[classnames[label[0]]] += 1\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "class_counts = count_labels(train.labels, labels.values())\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.xticks(rotation=45)\n",
    "_ = plt.title(\"Distribution of classes in the TRAIN dataset\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset is not that well balanced, we can calculate the class weights based on the training distribution to increase the weight of rare samples in the loss. This way we can avoid, that our model actively learns the above class distribution and consequently focuses more on learning the difference between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**\n",
    "\n",
    "> Adapt the three last code lines in the cell above to display the class labels distribution in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# add your code here ..."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Click on the dots to display the solution**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "class_counts = count_labels(val.labels, labels.values())\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.xticks(rotation=45)\n",
    "_ = plt.title(\"Distribution of classes in the VALIDATION dataset\")\n",
    "plt.show()\n",
    "\n",
    "class_counts = count_labels(test.labels, labels.values())\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.xticks(rotation=45)\n",
    "_ = plt.title(\"Distribution of classes in the TEST dataset\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It looks like the distributions are the same over all splits, so we do not have to adjust the class weights."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train.labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we may not have a GPU available, we will illustrate the procedure with rather small models. Our goal is not to get optimal performance on the dataset, but to showcase the procedure and tools for setting up the training of a CNN for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the image size to define our model inputs. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_shape = train.imgs[0].shape\n",
    "input_shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is 64 pixels wide and tall and has 3 channels (RGB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**\n",
    "> Build a CNN model using `models.Sequential`, `layers.Conv2D`, `layers.MaxPool2D`, `layers.Flatten()`, `layers.Dense`\n",
    "> It should follow the following structure:\n",
    "> * 3 convolution layers (2D) with max-pooling\n",
    ">     1. 32 filters, 3x3 kernel, ReLU, 2x2 max-pooling \n",
    ">     2. 64 filters, 3x3 kernel, ReLU, 2x2 max-pooling  \n",
    ">     3. 64 filters, 3x3 kernel, ReLU, 2x2 max-pooling \n",
    "> * 2 Fully connected layers\n",
    ">     1. 128 neurons, ReLU\n",
    ">     2. Number of output classes as neurons and softmax activation\n",
    ">\n",
    "> After the convolutional layers you will need to flatten the output to pass it to a fully-connected layer.\n",
    "> Look up the corresponding function in the keras docs https://keras.io/api/layers/."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tf.random.set_seed(842)\n",
    "\n",
    "model = models.Sequential([\n",
    "    ### START YOUR CODE ###\n",
    "    # ...\n",
    "    ### END YOUR CODE ###\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Click on the dots to display the solution**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tf.random.set_seed(842)\n",
    "\n",
    "model = models.Sequential([\n",
    "    ### START YOUR CODE ###\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(len(labels), activation=\"softmax\"),\n",
    "    ### END YOUR CODE ###\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model, using an optimizer, a loss function and desired metrics and provide an optimizer that performs gradient descent with a defined learning rate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "learning_rate = 5e-5\n",
    "opt = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[\"sparse_categorical_accuracy\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some helper functions to get the model weights for visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_filter_weights(model: models.Sequential):\n",
    "    filters = []\n",
    "    for layer in model.layers:\n",
    "        if 'conv' not in layer.name:\n",
    "            continue\n",
    "        f, _ = layer.get_weights()\n",
    "        print(layer.name, f.shape)\n",
    "        filters.append(f)\n",
    "    return filters"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "untrained_filters = get_filter_weights(model)\n",
    "untrained_filters[0].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation of images with standardisation, rotation and flipping to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10, horizontal_flip=True, vertical_flip=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model by providing it the imagedatagenerator with our training data. We can use the early-stopping callback to stop the training once our validation scores have not improved in the last 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "source": [
    "tf.random.set_seed(42)\n",
    "start = time.monotonic()\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               mode='min',\n",
    "                                               patience=20,\n",
    "                                               restore_best_weights=True)\n",
    "model.fit(datagen.flow(train.imgs, train.labels, batch_size=32),\n",
    "          validation_data=(val.imgs, val.labels),\n",
    "          shuffle=True,  # images provided by BloodMNIST should be shuffled, but we do it again just to be sure\n",
    "          epochs=100,\n",
    "          callbacks=[early_stopping])\n",
    "train_time_s = time.monotonic() - start\n",
    "print(f\"Training time (s): {timedelta(seconds=train_time_s)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "show_history_plots_of_trained_model(model.history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we evaluate our model. First we have to calculate the probabilities and labels on the test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "true_labels = test.labels[:, 0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Generate the predicted labels using your trained model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### START YOUR CODE ###\n",
    "predicted_probabilities = ...\n",
    "predicted_labels = ...\n",
    "### END YOUR CODE ###"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Click on the dots to display the solution**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "predicted_probabilities = model.predict(test.imgs, verbose=0)\n",
    "predicted_labels = np.argmax(predicted_probabilities, axis=-1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scikit-learn, we can create a classification report that includes all important metrics off-the-shelf."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "report = classification_report(\n",
    "    true_labels,\n",
    "    predicted_labels,\n",
    "    target_names=list(labels.values()),\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {report['accuracy']}\")\n",
    "metrics = {k: v for k, v in report.items() if k not in ['accuracy']}\n",
    "df_report = pd.DataFrame(metrics).transpose()\n",
    "df_report = df_report[['precision', 'recall', 'f1-score', 'support']].round(4)\n",
    "df_report"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "ConfusionMatrixDisplay(matrix, display_labels=list(labels.values())).plot(cmap=plt.cm.Blues)\n",
    "tick_marks = np.arange(len(list(labels.values())))\n",
    "plt.xticks(tick_marks, list(labels.values()), rotation=45)\n",
    "_ = plt.yticks(tick_marks, list(labels.values()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature maps in Convolutional Neural Networks (CNNs) provide valuable insights into how the network processes and understands input data. They represent the output of convolutional layers and capture specific features or patterns in the input."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_idx = 20\n",
    "example_label = train.labels[example_idx][0]\n",
    "print(labels[example_label])\n",
    "example_image = train.imgs[example_idx]\n",
    "plt.imshow(example_image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "layer_1_model = models.Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "feature_map_layer_1 = layer_1_model.predict(np.expand_dims(example_image, 0))[0].T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feature_map_layer_1.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_feature_maps(feature_maps, figsize=(10, 10)) -> None:\n",
    "    num_maps = len(feature_maps)\n",
    "    num_rows = np.ceil(np.sqrt(num_maps)).astype(int)\n",
    "\n",
    "    # Create a figure to display the filters\n",
    "    fig, axes = plt.subplots(num_rows, num_rows, figsize=figsize)\n",
    "\n",
    "    for i in range(num_maps):\n",
    "        ax = axes[i // num_rows, i % num_rows]\n",
    "        ax.imshow(feature_maps[i], cmap='gray', label=f\"Feature map {i}\")\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for i in range(num_maps, num_rows * num_rows):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_feature_maps(feature_map_layer_1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind activation maximization is to generate input data that leads to the highest possible activation for a particular neuron or filter within the network.\n",
    "By examining the inputs that maximize activations, we can gain insights into what specific features or patterns different neurons are sensitive to."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets try it for neutrophils, an example of a neutrophil below"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(example_image)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since filter at index 4 looks interesting, we will try to maximize its activation."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "activation_maximization = ActivationMaximization(model,\n",
    "                                                 model_modifier=[ExtractIntermediateLayer(-1),\n",
    "                                                                 ReplaceToLinear()],\n",
    "                                                 clone=True)\n",
    "rotator = Rotate2D(degree=2)\n",
    "rotator.random_generator = np.random.default_rng(123)\n",
    "activations = activation_maximization(CategoricalScore(example_label),\n",
    "                                      steps=200,\n",
    "                                      input_range=(0.0, 1.0),\n",
    "                                      input_modifiers=[Jitter(jitter=10), rotator],\n",
    "                                      optimizer=tf.keras.optimizers.AdamW(learning_rate=0.5),\n",
    "                                      callbacks=[Progress()]).cpu().numpy()\n",
    "\n",
    "plt.imshow(activations[0], cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.imshow(example_image)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this exercise we have trained a CNN model for the classification of blood cells. We have used the medmnist dataset and a simple model architecture. We have also evaluated the model and visualized the feature maps and activations of the model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
